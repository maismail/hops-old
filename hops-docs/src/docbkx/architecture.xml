<?xml version="1.0" encoding="UTF-8"?>
<chapter version="5.0" xmlns="http://docbook.org/ns/docbook"
         xmlns:xlink="http://www.w3.org/1999/xlink"
         xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:ns5="http://www.w3.org/2000/svg"
         xmlns:ns4="http://www.w3.org/1998/Math/MathML"
         xmlns:ns3="http://www.w3.org/1999/xhtml"
         xmlns:db="http://docbook.org/ns/docbook"
         xml:id="ch07">
    <title>Hop Architecture</title>
    <sect1>
        <title>Highly Available Hadoop Filesystem (HDFS)</title>
        <para>
            Due to the rapid growth of data in recent years, distributed file systems have
            gained widespread adoption. The new breed of distributed file systems reliably store
            petabytes of data, and also provide rich abstractions for massively parallel data analytics. 
            The Hadoop Distributed File System (HDFS) is a 
            distributed, fault-tolerant file system designed to run on 
            low-cost commodity hardware that scales to store petabytes of data, 
            and is the file storage component of the Hadoop platform. 
            HDFS provides the storage layer for MapReduce, Hive, HBase, Spark and all other 
            YARN applications, see <xref linkend="hadoop2"/>.
            <figure xml:id="hadoop2">
                <title>Hadoop v2</title>
                <mediaobject>
                    <imageobject>
                        <imagedata fileref="media/hadoop2.png" scale="40" align="center"/>
                    </imageobject>
                </mediaobject>
            </figure>
            
            In 2013, HDFS v2 introduced a new highly available metadata architecture, where, as
            in HDFS v1, the entire filesystem's metadata is stored in memory on a single node, but in v2
            changes to the metadata (<emphasis>edit log entries</emphasis>) are now replicated 
            and persisted to a set of (at least three) Journal Nodes using a quorum-based replication algorithm.
            In HDFS v2, a Primary and Secondary NameNode can be configured, where the Primary NameNode is 
            responsible for managing the metadata, and the Secondary NameNode 
            keeps an eventually consistent copy of the metadata. The Secondary NameNode 
            is kept in sync with the Primary by two mechanisms: firstly, by asynchronously applying all 
            edit log entries that have been committed at the Journal Nodes, and 
            secondly, receiving the same set of heartbeats from Data Nodes that are 
            received by the Primary.
            The Primary/Secondary replication model is also known as an Active/Standy or 
            Master/Slave replication model, and was popularized by databases in the 1990s. HDFS' 
            implementation of this eventually consistent replication model is more limited than in
            the traditional relational database world, as all read and write requests are sent to 
            the Primary. In typical Master/Slave configurations, writes are sent to the master, while
            reads are load-balanced across slaves.
            The reason all write requests are sent to the Primary to ensure a single consistent copy of the metadata. 
            Read requests are also sent to the Primary, as reads at the Secondary could result in operations being executed
            on stale metadata. This is a bigger problem for a filesystem, such as HDFS, 
            than it would be for a Web 2.0  social media application with non-critical data, 
            using a Master/Slave database setup. Thus, reads are only sent to the Primary. 
            If the Primary fails, however, 
            the Secondary needs to take over as Primary. Before it can take over, it first has to 
            catch up with the set of edit log entries applied to Primary before it failed. 
            The period of time before all outstanding edit log entries are applied at the Secondary before
            it can take over may be up to tens of seconds, depending on the current load of the system and
            the hardware and software setup.
            Another limitation of the Primary/Secondary model, is that client and Data Nodes from 
            HDFS need to have a consistent view of who the current Primary NameNode is. They do this by 
            asking a Zookeeper coordination service that needs to run on at least 3 nodes to provide a fault
            tolerant reliable service. Finally, the concurrency model supported by HDFS v2 is still 
            multiple-readers, single-writer.
            <figure xml:id="hdfsv2">
                <title>HDFS v2 NameNode Primary/Secondary Replication Model</title>
                <mediaobject>
                    <imageobject>
                        <imagedata fileref="media/hdfsv2.png" scale="50" align="center"/>
                    </imageobject>
                </mediaobject>
            </figure>
        </para>
        <para>
            In contrast, our implementation of HDFS, called Hop HDFS, replaces the 
            Primary-Secondary metadata model with shared, transactional memory, 
            implemented using a distributed, in-memory, shared-nothing database, MySQL Cluster, 
            see figure <xref linkend="hop-hdfs"/>.
            In our new model, the size of HDFS' metadata is no longer limited 
            to the amount of memory that can be managed on the JVM of a single node.
            Our solution involves storing the metadata in a replicated, distributed, in-memory
            database that can scale up to several tens of nodes, all while maintaining 
            the consistency semantics of HDFS.  We maintain the consistency of the metadata, 
            while providing high performance, all within a multiple-writer, multiple-reader
            concurrency model. Multiple concurrent writers are now supported for the filesystem
            as a whole, but single-writer concurrency is enforced at the inode level.
            Our solution guarantees freedom from deadlock and progress by
            logically organizing inodes  (and their constituent blocks and replicas) into a hierarchy and having transactions 
            defining on a global order for transactions acquiring both explicit locks and 
            implicit locks on subtrees in the hierarchy. 
            The use of a database, however, also has its drawbacks. As the data now resides
            on remote hosts on the network, an excessive number of roundtrips to 
            the database harms system scalability and increases per-operation latencies.
            We ameliorate these problems by introducing a snapshotting mechanism 
            for transactions, where, at the beginning of a transaction, 
            all the resources it needs are aquired in the defined global order, while
            simulatenously taking row-level locks for those resources. On transaction
            commit or abort, the resources are freed. This solution enables NameNodes
            to perform operations on a local copy (or snapshot) of the transactions
            state until such time as the transaction is completed, thus reducing
            the number the number of roundtrips to the database, see <xref linkend="hdfs-snapshot"/> . 
        </para>
        <figure xml:id="hop-hdfs">
            <title>Hop HDFS</title>
            <mediaobject>
                <imageobject>
                    <imagedata fileref="media/hop-hdfs.png" scale="50" align="center"/>
                </imageobject>
            </mediaobject>
        </figure>    

    </sect1>

    <sect1>                                
        <title>Leader Election</title>
        In HDFS, there are a number of background tasks that are problematic if
        multiple NameNodes attempt to perform them concurrently. Examples of such
        tasks include: 
        <orderedlist>
            <listitem>
                replication monitoring, 
            </listitem>
            <listitem>
                lease management,
            </listitem>
            <listitem>
                block token generation,
            </listitem>
            <listitem>
                and the decomissioning of datanodes.
            </listitem>
        </orderedlist>
        To clariy the problem, we give an exapmle. Without any coordination between 
        NameNodes, and since all NameNodes have identical behaviour, 
        if a block becomes under-replicated, several NameNodes may identify
        this event, and each would select a DataNode to replicate that block to. This would
        cause multiple re-replications of the block, leading it to enter an over-replicated
        state, upon which, multiple NameNodes would recognize this over-replicated state and attempt
        to remove replicas, possibly leading to an under-replicated block - back where 
        we started. 

        We solve this coordination problem, by implementing a Leader Election Algorithm,
        where only the leader NameNode is assigned the task of performing the above background tasks.
        Our leader election algorithm uses the shared, transactional memory 
        abstraction provided by MySQL Cluster to coordinate the election process.

        <para/>
        <emphasis>Definition: Correct NameNode process</emphasis>
        <para>
            The notion of correct in this context means that a process is active and 
            running and is able to connect and write to NDB cluster in a bounded time interval.
            The bounded time interval is typically set to around 1 second, and we call such
            an interval a <emphasis>round</emphasis>. 
        </para>

        A leader NameNode is a NameNode from the set of NameNodes that  
        is correct and is responsible for listening to DateNode heartbeats and 
        assigning various tasks to them as well as responsible for managing background tasks.
        The properties that our leader election algorithm guarantee are:
        <orderedlist>
            <listitem>
                <emphasis>Completeness:</emphasis> after a bounded time interval, all correct NameNodes will detect every NameNode that has crashed.
                <emphasis>Agreement:</emphasis> after a bounded time interval, all correct NameNodes will recognize one among them as the leader.
                All will agree to the same NameNode being the leader.
<emphasis>Stability:</emphasis> If one correct NameNode is the leader, all previous leaders have crashed
            </listitem>
        </orderedlist>
        <para/>
        <emphasis>Leader Election Algorithm</emphasis>
        <para>
            The leader election algorithm runs continuously at the NameNodes. 
            Each NameNode is assigned an (integer) id. 
            At any point in time, the correct NameNode with the lowest id is 
            elected as the leader. The central focus of the algorithm is to detect failures 
            and elect a new leader using heartbeats. We implement heartbeats as counters in 
            a table in NDB. The algorithm is run at NameNodes in rounds (every nth second), 
            and it is expected that each NameNode will send only one heartbeat per round, 
            although our algorithm tolerates minor deviations, as explained later. 
            NameNodes can discover who the leader is by reading the ids of correct 
            NameNodes from a table in NDB. NDB's shared transactional memory 
            allows all NameNodes to have a uniform view of the correct NameNodes in the system. 
            We implemented our heartbeat model using the schema shown in <xref linkend="leader"/>. Some
            sample records are also shown to show an example run of the algorithm.
        </para>
        <figure xml:id="leader">
            <title>Leader Table in NDB</title>
            <mediaobject>
                <imageobject>
                    <imagedata fileref="media/leader.png" scale="66" align="center"/>
                </imageobject>
            </mediaobject>
        </figure>    

        <para>
            Once a NameNode starts, it starts a rounds timer which periodically triggers
            causing it to send a heartbeat to the NDB to indicate 
            that it is currently active and running. The heartbeat is implemented by
            a NameNode first reading the highest counter value in a LEADER table and
            then updating its counter value in the LEADER table to be one higher than
            the current highest counter value. A heartbeat, in effect, increments
            the highest counter value. Heartbeats should be loosely synchronized by
            configuring hosts to use Network Time Protocol, and setting equivalent timeouts
            for triggering heartbeats at nodes.
            To ensure serialized updates to counter values, when each NameNode 
            reads the highest counter value, it acquires a table-level write lock on 
            the LEADER table and only releases this lock after
            it has updated its own counter value. All of these operations happen within 
            a transaction, so that the lock is released in the event of a NameNode 
            failure while updating the LEADER table. 
        </para>
        <emphasis>Case-I: Failure-free scenario</emphasis>
        In the case of no failures, after each round when all NameNodes have successfully
        sent heartbeats, the highest value of the counter should have increased
        by the number of correct NameNodes, and the value of each NameNode's counter 
        should have increased by approximately the number of correct NameNodes.
        We say approximately, as clock skew, network delays, and congestion may cause updates 
        to arrive at varying times within a round. Assuming clock skews are not as 
        large as the heartbeat interval and no congestion, all
        NameNodes should succeed in sending one heartbeat at least every 2 rounds.
        The above figure shows an example of counter values for 3 NameNodes 
        with ids 1, 2 and 3 and their corresponding counter values as 23, 24 and 25 respectively.
        For brevity, we designate a NameNode with an id of value x as NNx. From this 
        example we see that NN1 has the lowest id and is therefore elected as the current leader in
        the system.
        <para/>
        <emphasis>Case-II: Leader crash scenario</emphasis>
        <para>
            For numerous reasons, a NameNode may fail in sending a heartbeat to NDB 
            a round, and, thus, fail to update its counter 
            value in the LEADER table. The counter value for the NameNodes remains 
            the same Namenodes would experience an irregular sequence of
            counter values in each of these rows. For example, let’s say that NN1 
            has crashed and the current counter value is now 6. This would allow 
            NN2 and NN3 to progress in updating the counter with values 9 and 10 
            while counter value for NN1 is still at value 6. In  <xref linkend="leader-example"/>, 
            we can see a snapshot of the view on the LEADER table at this round (T0).
            The figure shows non-consecutive counter values 6, 9 and 10 when we 
            would expect something like 8, 9 and 10. As all NNs have a consistent view of these
            counter values, so NN2 and NN3 can now agree that NN1 has crashed, and NN2 will 
            become leader.
        </para>

        <figure xml:id="leader-example">
            <title>Leader Table in NDB</title>
            <mediaobject>
                <imageobject>
                    <imagedata fileref="media/leader-example.png" scale="50" align="center"/>
                </imageobject>
            </mediaobject>
        </figure>    


        <para/>
        <emphasis>Determining the leader</emphasis>
        <para>
            The next step is to detect an irregular sequence of counter values and to
            decide if a new leader is to be elected. 
            The basic idea to determine the leader is to determine which NameNode 
            have counter values close enough to the current highest counter value to be
            considered 'correct'. In the example given above, the highest counter value 
            at round T2 (bottom table) is 11.
            As we have 3 NameNodes in the system, we expect the counter values to
            be in the range [9-11], although allowing for out-of-order heartbeats, 
            the counter values could be in the range [7-10]. The upper-bound on 
            out-of-order updates to counters is, by default, 2 rounds. That means
            that a NameNode that is more than 2 rounds behind in updating its counter
            value is no longer considered to be correct.
            In the lower table, we can see that NN1 is now no longer considered correct,
            as both NN2 and NN3 have succeeded in updating their counters 3 times 
            before NN1 has updated its counter. Therefore, NN2 now becomes the new 
            leader, as its counter value is within the range of 2 rounds from the max
            counter value, and it has the lowest id of the remaining correct NNs.
            Both NN2 and NN3 independently reach a decision about the new leader, NN2,
            the next time they try to update their own counter.
        </para>

        <para/>
        <emphasis>Ensuring single leader dominance</emphasis>
        <para>
            Once a NameNode determines that it is the leader, the first thing it does
            is to ensure that there are no other leaders in the system. This 
            means that all previously elected leaders (or NameNodes with ids lower
            than its own) have crashed. To ensure this, it enforces this rule by 
            removing all records from the [LEADER] table for NNs with a lower id than 
            its own.
        </para>
        <!--        <para/>
        <emphasis>Correctness</emphasis>
        <para>
        The following are the cases that prove correctness of the algorithm
        Case-I: Scenario when current leader crashes
        Supposing we have three NameNodes, each have the current counter as [NN1=6, NN2=7, NN3=8].
        We assume NN1 has crashed and therefore will not update its counter. In the next round, NN2 will
        update the counter to 9 and later NN3 would update the counter to 10 and we would have the
        following state information for NNs to agree on [NN1=6, NN2=9, NN3=10].
        </para>-->

        <example xml:id="leader-election-NNs">
            <title>Leader Election Algorithm at NameNodes</title>
            <programlisting linenumbering="numbered">
function updateCounter()
retrieve ([COUNTER], counter)
increment counter
store([COUNTER], counter)

// The entry for this NN may not exist if it crashed 
// and was removed by another leader
if(!exists([LEADER], id) then 
id = retrieve([LEADER], max(id)) + 1
end if

store([LEADER], id, counter)

// The function that determines the current leader
function select()
SELECT id FROM [LEADER]
WHERE counter  (max(counter) – count(id)) // returns all correct NNs
LIMIT 1 /*selects lowest id*/
return id

// The function that returns the list of correct NNs
function selectAll()
SELECT id FROM [LEADER]
WHERE counter &gt; (max(counter) – count(id)) // returns all correct NNs
ORDER BY id                              // the leader has the lowest id
return list(id)

upon event &lt;init&gt; do
leader = NIL
updateCounter()
leader = select()

// After every interval, the NameNode updates the counter
upon event &lt;check&gt;
updateCounter()
leader = select()
// If this NN is elected the leader, remove previous leaders
if(leader == id) then
remove([LEADER],[ids &lt; leader])
end if

upon event &lt; timeout&gt;
// Kill NN on timeouts, so DNs can connect to the next leader NN
shutdown()

// Return the list of correct NNs in order of lowest ids
upon event &lt;heartbeats&gt;
return selectAll()
            </programlisting>
        </example>

        <example xml:id="leader-election-DNs">
            <title>Detecting the Leader at DataNodes</title>
            <programlisting  linenumbering="numbered">
        // The NN leader id is passed in upon initialization of DN
        upon event init&lt;list(id)&gt;
        nnlist = list(id)
        // The NN with the lowest id is the leader
        leader = min(nnlist)

        // Update the list of NNs on every heartbeat response from Leader NN
        upon event &lt;heartbeat-response, list(id)&gt;
        nnlist = list(id)
        leader = min(nnlist)

        // On timeout from leader NN
        upon event &lt;timeout&gt;
        // remove current leader from nnlist
        remove(nnlist, leader)
        // elect a new leader
        leader = min(nnlist)
            </programlisting>
        </example>

        <!--        <para>
        Let’s say that NN1 crashes as soon as it updated its counter to 6. In the same round, NN2 updates its
        counter to 7 with a counter range of [5-7] and NN3 would update its counter to 8 with a counter range
        of [6-8]. At this point, from both NameNode perspectives, NN1 is alive as its counter lies in the range
        while the DataNodes detect failure of NN1 via the TCP socket. 
        Now, in the next round, NN2 would progress to updating the counter to 9 and now the counter range
        would be [7-9]. Thus at this round, it would detect the crash of NN1 because the counter pertaining to
        NN1 is still 6 and does not lie in this range.
        Similarly, when NN3 updates the counter to 10 it detects the crash of NN1 because the range of
        counter values is [8-10]. This means that at this point, both NN2 and NN3 recognizes the crash of
        NN1 and run the consensus to elect the leader. NN2 having the lowest id would be elected as the
        leader. Thus [Property#1] holds.
        Now, when NN2 is elected the leader, it removes all lower NN ids in comparison to its own id from
        the table. So now it has the lowest id and all NNs will see this view. This forces [Property#2] where
        all previous leaders have now crashed. This is illustrated above in Figure7.
        If the previous leader recovers, it notices that its id is not in the table as the lowest id and will place its
        record with the next highest id.
        DNs recognizing the new leader
        </para>-->
        <para>
            All DataNodes are kept up-to-date with the current view of NameNodes in the system. This is done via
            requesting the NameNodes for the current list of NameNodes. This is done via a simple RPC call. The
            DataNodes get the list of NameNodes and assume the NameNode with the lowest id is the leader.
            When NN1 had crashed, the DNs keep retrying for some amount of time and if they are not
            successful at making contact with the NN it will remove it from the list and select the next NN who
            could potentially be the leader. This would achieve [Property#2].
            There can be two possibilities where (a) the DataNode contacts the next NN and if it is actually the
            leader then the process flows normally. (b) The DataNode contacts the next NN in the list but who may
            not be the leader (because it is possible that it has also crashed or a new NN has joined with a lower id).
            This NN would then either provide the updated list of NameNodes, including the new leader, or not respond due
            to failure. THe DataNode can continue querying all NameNodes until either it
            is returned a list of correct nodes (including the id of the leader) or
            all NameNodes have failed.
            If there is a correct NameNode, eventually all correct DNs would recognize 
            a correct NN as the leader thereby fulfilling [Property#1].
        </para>
        <para>
            Case-II: Scenario when current leader thinks it is alive but cannot connect to NDB cluster
            If NN1 is active and running, but it cannot update the LEADER table in NDB, then such a NameNode
            is not considered correct as per definition. In this scenario, all DataNodes 
            would always think that NN1 is the current leader as it can make
            contact with that NN. But since the NN cannot update NDB, it has to kill itself and
            shutdown (or restart) hoping that some other NameNode would eventually be elected the leader.
            When NN1 is shutdown, DataNodes will keep retrying for some amount of time after some
            point where they will switch to the next NameNode and try to determine the next NN leader.
        </para>
    </sect1>

    <sect1>                                
        <title>Ensuring Correctness of HDFS</title>
            One of the main challenges in migrating HDFS' metadata from the heap of
            a single JVM to a relational database was ensuring the correctness of 
            our approach. From a practical perspective, we ensure correctness by
            ensuring that we have (almost) no failing unit tests from the extensive
            suite of over 300 unit tests.
            From a theoretical perspective, our solution provides for support for multiple
            concurrent writers, so we need to show that our solution is free of both
            deadlock and livelock.

        <para/>
        <emphasis>Transactions and Isolation Levels</emphasis>
        <para>
            We implemented each HDFS operation as a single transaction, where we begin the transaction, 
            read and write the necessary meta-data from NDB, and then either commit, 
            or in the case of failure, abort the transaction and then possibly re-try
            the transaction. A general, cheap, and widely supported transaction isolation level,
            and the only isolation level supported by NDB, is read-committed, 
            which allows the results of write operations in transactions 
            to be exposed to read operations in different concurrent transactions. 
            However, the read-committed isolation level allows anomalies which would
            break the consistency of our file-system operations, such as
            Fuzzy Reads, Phantom reads, Lost Update, Read Skew and Write Skew [berenson1995critique]. 
         </para>           
         
        <para/>
        <emphasis>Hierarchy of Resources</emphasis>
        <para>
            Filesystems, such as HDFS, have hierarchical namespaces, with directories
            containing zero to many files, and, in unix-based filesystems, both 
            files and directories represented as inodes. In HDFS, when an inode represents
            a file, the inode may be made up of a variable number of fix-sized blocks 
            (typically 512 MB).
            
            We ensure deadlock freedom, by ensuring that all transactions lock
            inodes in a consistent order, defined by the filesystem's hierarchy: 
            the appropriate read or write locks are taken at inodes, starting at 
            the root and traversing directories in a depth-first, left-most order 
            until all the inode locks required for this transaction have been acquired.
            The locks are then held for the duration of the transaction. 
            Locks are not upgraded within a transaction. 
            Since all transactions acquire locks in the same order, there are 
            no cycles, and since locks are not upgraded, there will be no 
            lock-upgrade deadlocks.
            
            Locks also need to be acquired on data-structures used by inodes, such
            as blocks, replicas, leases, corrupted-blocks, etc.
            When operations are performed on inodes, we take a write lock on the
            inode itself, ensuring no other transactions can concurrently access
            that inode.
         </para>           
    </sect1>

    <sect1>                                
        <title>Snapshot layer</title>

    </sect1>

    <sect1>                                
        <title>Early performance measurements for HDFS</title>
        <para>Our early performance figures show that our version of HDFS can scale to handle a similar number
            of read and write requests per unit time as Apache HDFS (unpublished). We have introduced a number of
            features to enable this high level of performance, including a snapshot layer at
            NameNodes and row-level locking at the database level, rather than a system level lock
            for update operations as is done in Apache HDFS. Our snapshotting layer involves a
            transaction acquiring all resources it requires at the start of a primitive filesystem
            operation, and performing local read/write operations on the snapshot copy, and then
            finally committing or rolling back on transaction commit. </para>
        <figure xml:id="hdfs-snapshot">
            <title>Reduction in the DB roundtrips by snapshotting metadata at the NameNodes</title>
            <mediaobject>
                <imageobject>
                    <imagedata fileref="media/hdfs-snapshot.png" scale="66" align="center"></imagedata>
                </imageobject>
            </mediaobject>
        </figure>    
            For improved performance, we implement schema-aware partitioning of metadata across 
            multiple hosts, ensuring all data related to a single inode hashes
            to the same host, and can be retrieved in a single network hop.

        <!--        <figure xml:id="hdfs-locking">
            <title>Effect of replacing a global lock with row-level locks.</title>
            <mediaobject>
                <imageobject>
                    <imagedata fileref="media/hdfs-locking.png" scale="100" align="center"></imagedata>
                </imageobject>
            </mediaobject>
        </figure>            -->
    </sect1>    
        
    <sect1>
        <title>Platform-as-a-Service support: Hop</title>
        <para>Hop, as a cloud patform for distrbuted processing and big data, is made up of latest Hadoop ecosystem. As you 
            can see in <xref linkend="arch-stack"/> there are three major layers in our stack, HDFS, YARN and Workflow. 
            Cross-layer aspects like Security and PaaS services are also included.</para>

        <figure xml:id="arch-stack">
            <title>Hop stack</title>
            <mediaobject>
                <imageobject>
                    <imagedata fileref="media/arch-stack.png" scale="70" align="center"></imagedata>
                </imageobject>
            </mediaobject>
        </figure>    
        <para>.</para>
        <orderedlist>
            <listitem>
                <para>
                    <emphasis>Hop File System (Hop-FS)</emphasis>
                    At the bottom layer of big data stack is Hop-FS a distributed file system based on Hadoop Distributed File System (HDFS). We revisited relational 
                    representation of metadata to remove limitation of single metadata server and single point of failure. Our File System solution can scale up to several tens 
                    of nodes, while maintaining the consistency semantics for the filesystem. We store the metadata on a shared-nothing, in-memory, partitioned database by 
                    maintaining the consistency of the metadata, while providing high performance. Hop-FS also guarantees freedom from deadlock and progress.
                </para>
            </listitem>
            <listitem>
                <para>
                    <emphasis>MySQL Cluster</emphasis>
                    MySQL Cluster is a higly scalable, real-time, ACID-complaint transactional database.
                    Designed around a distributed, multi-master architecture with no single point of failure;
                    MySQL Cluster's real-time design delivers predictable, milisecond response times with 
                    the ability to service millions of operations per second. In the case of our data platform, it is
                    used to handle and manage the state of our multi-NameNode solution of our architecture.                                    
                </para>
            </listitem>
            <listitem>
                <para>
                    <emphasis>YARN</emphasis>
                    Resource negotiator for managing high volume distributed data processing tasks against HDFS. 
                    It supports different processing models other that Map-Reduce by separating its Resource 
                    Manager from Scheduler and Application Master. Application Master gives us flexibility to 
                    accommodate heterogeneous processes by implementing a wrapper for each kind of application 
                    so it could manage any kind of processing resources that is defined for it. This allows user 
                    to process data intensive task like MapReduce jobs or in our case our future support for 
                    bioinformatic workflow tasks engine which will make use of YARN to handle and negotiate the 
                    scheduling of this type of jobs.                                 
                </para>
            </listitem>
            <listitem>
                <para>
                    <emphasis>Workflow Engine</emphasis>
                    On top of YARN, HopS workflow engine parses workflows into an execution model of arbitrary tasks. 
                    For each task, it asks YARN for a containter, then for each container allocated task based on 
                    the scheduling policy it stages in data into HopSFS, launches the task and stages out the result 
                    back to HopSFS                                     
                </para>
            </listitem>
        </orderedlist>
    </sect1>

  
    <sect1>
        <title>Deployment model</title>
        <para>At the moment Hop supports Amazon Cloud, Open Stack and Bare Metal. Based on the
            chosen cloud provider, as it can be seen in <xref linkend="arch-deploy"/> our deployment
            model consist of Hop-Dashboard plus other machines either virtual in cloud or bare
            metal. Dashboard is the point of administration with web access through which customer
            could define configuration of the cluster, machines are allocated, their software stack
            is installed and state of the cluster is monitored. Cloud machines could be associated
            into security node-groups, machines inside each node-group basically have the same
            security credentials and could communicate with each other; however, communication
            between machnies from different security group is not possible. All the machins inside
            the cluster have the same infrastructure and basic stack of softwares, althoug based on
            the services each machine shoul provide, arbitrary platform softwares are
            installed.</para>
        <figure xml:id="arch-deploy">
            <title>Deployment Model</title>
            <mediaobject>
                <imageobject>
                    <imagedata fileref="media/arch-deploy.png" scale="45" align="center"/>
                </imageobject>
            </mediaobject>
        </figure>
    </sect1>

    <sect1>
        <title>Hop: Hadoop Open Platform-as-a-Service</title>
        <para>We have a prototype implementation of a Platform-as-a-Service (PaaS) framework for HDFS.
            As our PaaS model will cover the whole Hadoop stack, and not just HDFS, we call it
            Hadoop Open Platform-as-a-Service, or <emphasis>Hop</emphasis> for short. Our framework is 
            <emphasis>open</emphasis>, as it is designed to be deployable on any cloud platform
            or a bare-metal environment. Currently, we support Amazon
            Web Services and OpenStack, as well as for bare-metal hosts.
            Hop consists of a set of frameworks and libraries that we use to deploy a Hadoop cluster 
            on both cloud and bare-metal clusters, with the most significant technologies
            being Chef and JClouds, but also including a YAML-compatible language for 
            defining a cluster and BitTorrent for improving download speeds of 
            programs to hosts in a cluster. 
            
            <figure xml:id="arch-helper">
                <title>Hop PaaS </title>
                <mediaobject>
                    <imageobject>
                        <imagedata fileref="media/arch-layers.png" scale="50" align="center"></imagedata>
                    </imageobject>
                    <caption>
                        <para>Hop PaaS Stack</para>
                    </caption>
                </mediaobject>
            </figure>
            <orderedlist>
                <listitem>
                    <para>
                        <emphasis>YAML</emphasis>
                        YAML (YAML Ain't  Markup Language) is markup language which takes concepts from
                        programming languages such as C, Perl and Python, and ideas from XML. 
                        We use YAML to define the set of hosts and the services that will be installed on 
                        those hosts, making up a single cluster. This way, we can define a whole cluster
                        in a single file, enabling easier management of clusters and even the sharing of
                        cluster definitions.
                        YAML syntax allows easy mappings of common data types found in high level languages like list, 
                        associative arrays and scalar. It makes it suitable for tasks where humans are likely to
                        view or edit data structures, such as configuration files or in our case, cluster
                        definition files. Additionally, we make use of the open source parser SnakeYAML to parse
                        the contents of our cluster definition files. The SnakeYAML parser transforms the given cluster 
                        definition into consecutive stages such as defining security groups, virtual machine 
                        allocation, bittorent, installation, validation and retry.
                        An example of a simple cluster definition is given in <xref linkend="example-cluster-defn"/>. 
                        The YAML file defines a cluster consisting of 6 nodes,
                        with MySQL Cluster running exclusively on 2 nodes, Hadoop running exclusively on 3 nodes, and
                        another node running both MySQL Cluster and Hadoop services. The example uses default
                        values for the AWS image, instanceType and region. There are many other parameters that 
                        can be overriden. Our services map directly onto chef recipes for installing the services. We
                        are developing a model for explicitly handling dependencies in chef, so that dependent services
                        such as Java don't need to be specified as requirements in this cluster definition file.
                            
                        <example xml:id="example-cluster-defn">
                            <title>Example Cluster Definition</title>
                            <programlisting>
                                name: simpleCluster                 
                                provider:
                                name: aws-ec2
                    
                                nodes:
                                - service: 
                                - ndb::ndbd
                                number: 2

                                - service: 
                                - ndb::mgm, ndb::mysqld, hadoop::namenode
                                number: 1
          
                                - service: 
                                - hadoop::namenode
                                - hadoop::resourcemanager
                                number: 1
          
                                - service: 
                                - hadoop::datanode
                                - hadoop::nodemanager
                                number: 2
                            </programlisting>
                        </example>
                            
                    </para>
                </listitem>
                <listitem>
                    <para>
                        <emphasis>Apache JClouds</emphasis>
                        Apache JClouds is an open source multi-cloud api interface which allows us
                        to write reusable code for creating, destroying, and bootstrapping virtual machines (VMs)
                        on different cloud providers.
                        The same code can be configured to interact with Amazon, OpenStack, Azure, and Rackspace VMs,
                        and 26 other cloud providers. 
                        Through JClouds simple Java interface, we can deploy and port Hop to different cloud 
                        environments. Hop parses cluster definition files, producing
                        code that executes JCloud API calls to create, destroy and bootstrap VMs.
                    </para>
                </listitem>
                <listitem>
                    <para>
                        <emphasis>Chef</emphasis>
                        Chef is a systems infrastructure and configuration framework 
                        that automates the deployment of servers and 
                        applications to any physical, virtual or cloud location. 
                        JClouds is used to bootstrap chef on VMs or physical hosts, and once
                        chef is installed on a host, we can run <emphasis>chef recipes</emphasis>
                        using the chef-client deployed on host to install software on that host.
                        The chef-client relies in a series of abstract definitions 
                        (defined as cookbooks and recopes) which are managed in Ruby and are treated like source code.
                        With each definition, we describe how a specific part should be built and managed, which then; the chef-client
                        applies these definitions to deploy and configure servers and applications as specified.
                        In most of the cases, it is simple enough to let chef-client know which cookbooks and recipes
                        it needs to apply.
                    </para>
                </listitem>
                <listitem>
                    <para>
                        <emphasis>BitTorrent</emphasis>
                        After machines are allocated in cloud, with the metadata information that JCloud returns, dashboard
                        tries to open a ssh connection into every single machine and install Chef agent for installations. 
                        Before installation starts, software libraries is replicated in all machines from dashboard, though 
                        the process could overflow the bandwidth to dashboard if all machines try to download from dashboard. 
                        To handle this situation HopS run a bittorent in which dashboard machine is the seeder, then all 
                        machnies could contribute to download process which is both faster and anti-bottleneck. After download 
                        Chef agent starts installation based on the required packages in each machine and with the order of 
                        dependencies between packages. 
                    </para>
                </listitem>
                <!--                <listitem>
                    <para>
                        <emphasis>Collectd</emphasis>
                        Collectd is a daemon which collects system performance statistics periodically and 
                        provides mechanisms to store values in a variety of ways like RRD files. Collectd 
                        gathers statistics about the system it is running and stores this information. With 
                        these statistics, we can keep track of the performance of your cluster and detect
                        possible failures and performance bottlenecks that might be needed to be address.
                    </para>
                </listitem>-->
            </orderedlist>
        </para>
    </sect1>
    
    <bibliography>
        <title>References</title>
        
        <bibliodiv>
            <biblioentry>
                <abbrev>AhoSethiUllman96</abbrev>
                <authorgroup>
                    <author>
                        <personname>
                            <firstname>Alfred V.</firstname>
                            <surname>Aho</surname>
                        </personname>
                    </author>
                    <author>
                        <personname>
                            <firstname>Ravi</firstname>
                            <surname>Sethi</surname>
                        </personname>
                    </author>
                    <author>
                        <personname>
                            <firstname>Jeffrey D.</firstname>
                            <surname>Ullman</surname>
                        </personname>
                    </author>
                </authorgroup>
                <copyright>
                    <year>1996</year>
                    <holder>Bell Telephone Laboratories, Inc.</holder>
                </copyright>
                <editor>
                    <personname>
                        <firstname>James T.</firstname>
                        <surname>DeWolf</surname>
                    </personname>
                </editor>
                <biblioid class="isbn">0-201-10088-6</biblioid>
                <publisher>
                    <publishername>Addison-Wesley Publishing Company</publishername>
                </publisher>
                <citetitle>Compilers, Principles, Techniques, and Tools</citetitle>
            </biblioentry>
            <!--</bibliolist>-->    
        </bibliodiv>

    </bibliography>
        
</chapter>
