<?xml version="1.0" encoding="UTF-8"?>
<section version="5.0" xmlns="http://docbook.org/ns/docbook"
         xmlns:xlink="http://www.w3.org/1999/xlink"
         xmlns:xi="http://www.w3.org/2001/XInclude"
         xmlns:ns5="http://www.w3.org/2000/svg"
         xmlns:ns4="http://www.w3.org/1998/Math/MathML"
         xmlns:ns3="http://www.w3.org/1999/xhtml"
         xmlns:db="http://docbook.org/ns/docbook">
    
    <section>
        <title>Hop Architecture</title>
        <para>Hops, as a cloud patform for distrbuted processing and big data, is made up of latest Hadoop ecosystem. As you 
            can see in <xref linkend="arch-stack"/> there are three major layers in our stack, HDFS, YARN and Workflow. 
            Cross-layer aspects like Security and PaaS services are also included.</para>

        <figure id="arch-stack">
            <title>Big Data stack</title>
            <mediaobject>
                <imageobject>
                    <imagedata fileref="media/arch-stack.png" width="6in" depth="5.5in" contentwidth="4in" contentdepth="3in"></imagedata>
                </imageobject>
            </mediaobject>
        </figure>    
        <para>At the bottom layer of big data stack, there is a new version of Hadoop Distributed File System, HOPSFS, with distributed NameNode. NameNodes' metadata has 
            relational representation which is stored in shared nothing, in-memory and replicated database, MySQL-Cluster. State-less NameNodes makes HOPS-FS highly available
            highly performant with the capacity of petabytes storage.</para>
        <para>YARN, new version of Hadoop, which is meant to support different processing models other that Map-Reduce by separating its Resource Manager from Scheduler and 
            Application Master. Application Master gives us flexibility to accommodate heterogeneous processes by implementing a wrapper for each kind of application so it could 
            manage any kind of processing resources that is defined for it. It enables HOPS platform to not be able to support end to end big workflow of big data, containing 
            map-reduce jobs or any other kind of jobs. </para>
        <para>On top of YARN, HOPS workflow engine parses workflows into an execution model of arbitrary tasks. For each task, it asks YARN for a containter, then for each
            container allocated task based on the scheduling policy it stages in data into HOPSFS, launches the task and stages out the result back to HOPSFS.</para>
    </section>

  
    <section>
        <title>Hop Basics</title>
        <para>Hop consists of multiple services:
            <itemizedlist>
                <listitem>
                    <para>
                        <emphasis>Core Platform:</emphasis> The basic components of our Hadoop distribution.
                        <orderedlist>
                            <listitem>
                                <para>
                                    <emphasis>Hadoop Distributed File System (HDFS):</emphasis>
                                    Hadoop provides high-throughput access to data in a highly distributed environment. 
                                    In our case our distribution is based on Hadoop version 2 release modified in order to offer 
                                    extended mechanism for more scalable and available namenode.
                                </para>
                            </listitem>
                            <listitem>
                                <para>
                                    <emphasis>MySQL Cluster:</emphasis>
                                    MySQL Cluster is a higly scalable, real-time, ACID-complaint transactional database.
                                    Designed around a distributed, multi-master architecture with no single point of failure;
                                    MySQL Cluster's real-time design delivers predictable, milisecond response times with 
                                    the ability to service millions of operations per second. In the case of our data platform, it is
                                    used to handle and manage the state of our multi-namenode solution of our architecture.                                    
                                </para>
                            </listitem>
                            <listitem>
                                <para>
                                    <emphasis>YARN:</emphasis>
                                    Resource negotiator for managing high volume distributed data processing tasks against
                                    HDFS. This allows user to process data intensive task like MapReduce jobs or in our case
                                    our future support for bioinformatic workflow tasks engine which will make use of YARN
                                    to handle and negotiate the scheduling of this type of jobs.                                     
                                </para>
                            </listitem>
                        </orderedlist>
                    </para>
                </listitem>
                <listitem>
                    <para>
                        <emphasis>Open Platform-as-a-Service:</emphasis> 
                        The key components behind our Open Platform-as-a-Service solution.
                        <orderedlist>
                            <listitem>
                                <para>
                                    <emphasis>Chef:</emphasis>
                                    Chef is a systems and cloud infrastructure automation framework based on Ruby 
                                    that simplifies deployment of servers and applications to any physical, virtual or cloud location
                                    no matter the size of the infrastructure. The chef-client relies in a series of abstract definitions 
                                    (defined as cookbooks and recopes) which are managed in Ruby and are treated like source code.
                                    With each definition, we describe how a specific part should be built and managed, which then; the chef-client
                                    applies these definitions to deploy and configure servers and applications as specified.
                                    In most of the cases, it is simple enough to let chef-client know which cookbooks and recipes
                                    it needs to apply.
                                </para>
                            </listitem>
                            <listitem>
                                <para>
                                    <emphasis>Apache JClouds:</emphasis>
                                    Apache JClouds is an open source multi-api interface which allows easy interaction 
                                    with multiple cloud providers and cloud software stacks. This open source api gives 
                                    support around 30 providers which include Amazon, Azure, OpenStack and 
                                    Rackspace. JClouds offers api implementations both in Java or Clojure.
                                    Through they simple interface, it is very simple to deploy and port your application
                                    over different cloud environments.            
                                </para>
                            </listitem>
                            <listitem>
                                <para>
                                    <emphasis>SnakeYAML and YAML:</emphasis>
                                    YAML (YAML Ain't  Markup Language) is markup language which takes concepts from
                                    programming languages such as C, Perl and Python, and ideas from XML. YAML syntax
                                    allows easy mappings of common data types found in high level languages like list, 
                                    associative arrays and scalar. It makes it suitable for tasks where humans are likely to
                                    view or edit data structures, such as configuration files or in our case, cluster
                                    definition files. Additionally, we make use of the open source parser SnakeYAML to parse
                                    the contents of our cluster definition files.
                                </para>
                            </listitem>
                        </orderedlist>
                    </para>
                </listitem>
                <listitem>
                    <para>
                        <emphasis>Hadoop Support:</emphasis> 
                        Set of components that allow easy monitoring your hadoop installation.
                        <orderedlist>
                            <listitem>
                                <para>
                                    <emphasis>Collectd:</emphasis>
                                    Collectd is a daemon which collects system performance statistics periodically and 
                                    provides mechanisms to store values in a variety of ways like RRD files. Collectd 
                                    gathers statistics about the system it is running and stores this information. With 
                                    these statistics, we can keep track of the performance of your cluster and detect
                                    possible failures and performance bottlenecks that might be needed to be address.
                                </para>
                            </listitem>
                        </orderedlist>
                    </para>
                </listitem>
            </itemizedlist>
        </para>
    </section>        

    
    <section>
        <title>Deployment model</title>
        <para>At the moment HOPS supports Amazon Cloud, Open Stack and Bare Metal. Based on the chosen cloud provider, as it can be seen in <xref linkend="arch-deploy"/> our deployment 
            model consist of Hops-Dashboard plus other machines either virtual in cloud or bare metal. Dashboard is the point of administration with web access through which customer 
            could define configuration of the cluster, machines are allocated, their software stack is installed and state of the cluster is monitored. Cloud machines could be associated
            into security node-groups, machines inside each node-group basically have the same security credentials and could communicate with each other; however, communication 
            between machnies from different security group is not possible. All the machins inside the cluster have the same infrastructure and basic stack of softwares, althoug based 
            on the services each machine shoul provide, arbitrary platform softwares are installed.</para>
        <figure id="arch-deploy">
            <title>Deployment Model</title>
            <mediaobject>
                <imageobject>
                    <imagedata fileref="media/arch-deploy.png" scale="50"></imagedata>
                </imageobject>
            </mediaobject>
        </figure>
    </section>

  
    <section>
        <title>Helper Stack</title>
        <para>Helpers are the intial set up on every machine that provide basics for cloud installation and configiration. On top of them, HOPML is an expressive, extendible 
            markup language that enables definition of the could platform. Its parser transforms the given cluster definition into consecutive stages such as defining security 
            groups, virtual machine allocation, bittorent, installation, validation and retry. All communications with cloud provider happens through JCloud service, each single
            configuration in HOPML may result in multiple JCloud instructions. After machines are allocated in cloud, with the metadata information that JCloud returns, dashboard
            tries to open a ssh connection into every single machine and install Chef agent for installations. Before installation starts, software libraries is replicated in all
            machines from dashboard, though the process could overflow the bandwidth to dashboard if all machines try to download from dashboard. To handle this situation HOPS run
            a bittorent in which dashboard machine is the seeder, then all machnies could contribute to download process which is both faster and anti-bottleneck. After download 
            Chef agent starts installation based on the required packages in each machine and with the order of dependencies between packages. 
        </para>
        <figure id="arch-helper">
            <title>Helper stack</title>
            <mediaobject>
                <imageobject>
                    <imagedata fileref="media/arch-layers.png" scale="50"></imagedata>
                </imageobject>
                <caption>
                    <para>Helper Stack</para>
                </caption>
            </mediaobject>
        </figure>
    </section>
    
    <section>
        <title>Orchestration Stack</title>
        <para>
            Our orchestration architecture makes use of multiple technologies in order to simplify the process
            of configuring and deploying a large cluster in the environment of their choice. This can be displayed
            as stack of technologies that interact between each other in order to succesfully configure a 
            cluster in the cloud.
        </para>
        <figure id="Orch-Stack">
            <title>Orchestration Stack</title>
            <mediaobject>
                <imageobject>
                    <imagedata fileref="media/stack.png" scale="50"></imagedata>
                </imageobject>
            </mediaobject>
        </figure>
    </section>

</section>
